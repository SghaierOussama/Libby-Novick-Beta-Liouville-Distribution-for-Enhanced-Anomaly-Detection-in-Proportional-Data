{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rUGw6b2-LJre"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from keras.datasets import mnist, fashion_mnist, cifar100, cifar10\n",
        "from keras.backend import cast_to_floatx\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u0MHJ4pVLoec"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.normalization.batch_normalization_v1 import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "random.seed(0)\n",
        "weight_decay = 0.000005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yi93ip8mLuBm"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "import itertools\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import apply_affine_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqege8c9MAiX"
      },
      "source": [
        "## **Load and Preprocessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JgXT02KNLzm6"
      },
      "outputs": [],
      "source": [
        "def resize_and_crop_image(input_file, output_side_length, greyscale=False):\n",
        "    img = cv2.imread(input_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB if not greyscale else cv2.COLOR_BGR2GRAY)\n",
        "    height, width = img.shape[:2]\n",
        "    new_height = output_side_length\n",
        "    new_width = output_side_length\n",
        "    if height > width:\n",
        "        new_height = int(output_side_length * height / width)\n",
        "    else:\n",
        "        new_width = int(output_side_length * width / height)\n",
        "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "    height_offset = (new_height - output_side_length) // 2\n",
        "    width_offset = (new_width - output_side_length) // 2\n",
        "    cropped_img = resized_img[height_offset:height_offset + output_side_length,\n",
        "                              width_offset:width_offset + output_side_length]\n",
        "    assert cropped_img.shape[:2] == (output_side_length, output_side_length)\n",
        "    return cropped_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MoWPCnk3MOa1"
      },
      "outputs": [],
      "source": [
        "def normalize_minus1_1(data):\n",
        "    return 2*(data/255.) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lHgParnmMRw7"
      },
      "outputs": [],
      "source": [
        "def get_channels_axis():\n",
        "  import keras\n",
        "  idf = keras.backend.image_data_format()\n",
        "  if idf == 'channels_first':\n",
        "      return 1\n",
        "  assert idf == 'channels_last'\n",
        "  return 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ygY-qVKqMVB3"
      },
      "outputs": [],
      "source": [
        "def load_mnist():\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = normalize_minus1_1(cast_to_floatx(np.pad(X_train, ((0, 0), (2, 2), (2, 2)), 'constant')))\n",
        "    X_train = np.expand_dims(X_train, axis=get_channels_axis())\n",
        "    X_test = normalize_minus1_1(cast_to_floatx(np.pad(X_test, ((0, 0), (2, 2), (2, 2)), 'constant')))\n",
        "    X_test = np.expand_dims(X_test, axis=get_channels_axis())\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZL18EvHMl8b"
      },
      "source": [
        "## **Saving the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g7NtHmLmMfoN"
      },
      "outputs": [],
      "source": [
        "def save_roc_pr_curve_data(scores, labels):\n",
        "    scores = scores.flatten()\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    scores_pos = scores[labels == 1]\n",
        "    scores_neg = scores[labels != 1]\n",
        "\n",
        "    truth = np.concatenate((np.zeros_like(scores_neg), np.ones_like(scores_pos)))\n",
        "    preds = np.concatenate((scores_neg, scores_pos))\n",
        "    fpr, tpr, roc_thresholds = roc_curve(truth, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc\",roc_auc)\n",
        "\n",
        "    # pr curve where \"normal\" is the positive class\n",
        "    precision_norm, recall_norm, pr_thresholds_norm = precision_recall_curve(truth, preds)\n",
        "    pr_auc_norm = auc(recall_norm, precision_norm)\n",
        "    print(\"pr_auc_norm where normal is the positive class\",pr_auc_norm)\n",
        "\n",
        "    # pr curve where \"anomaly\" is the positive class\n",
        "    precision_anom, recall_anom, pr_thresholds_anom = precision_recall_curve(truth, -preds, pos_label=0)\n",
        "    pr_auc_anom = auc(recall_anom, precision_anom)\n",
        "    print(\"pr_auc_norm where anomaly is the positive class\",pr_auc_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IEEuib19NZ26"
      },
      "outputs": [],
      "source": [
        "def get_class_name_from_index(index, dataset_name):\n",
        "    ind_to_name = {\n",
        "        'fashion-mnist': ('t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag',\n",
        "                          'ankle-boot'),\n",
        "    }\n",
        "\n",
        "    return ind_to_name[dataset_name][index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA18t2j0Mq9Z"
      },
      "source": [
        "## **Transformations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zOM4GuZqMqDS"
      },
      "outputs": [],
      "source": [
        "class AffineTransformation(object):\n",
        "    def __init__(self, flip, tx, ty, k_90_rotate):\n",
        "        self.flip = flip\n",
        "        self.tx = tx\n",
        "        self.ty = ty\n",
        "        self.k_90_rotate = k_90_rotate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        res_x = x\n",
        "        if self.flip:\n",
        "            res_x = np.fliplr(res_x)\n",
        "        if self.tx != 0 or self.ty != 0:\n",
        "            res_x = apply_affine_transform(res_x, tx=self.tx, ty=self.ty,row_axis=0,\n",
        "    col_axis=1, channel_axis=2, fill_mode='reflect')\n",
        "        if self.k_90_rotate != 0:\n",
        "            res_x = np.rot90(res_x, self.k_90_rotate)\n",
        "\n",
        "        return res_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1QRX0FkLMybA"
      },
      "outputs": [],
      "source": [
        "class AbstractTransformer(abc.ABC):\n",
        "    def __init__(self):\n",
        "        self._transformation_list = None\n",
        "        self._create_transformation_list()\n",
        "\n",
        "    @property\n",
        "    def n_transforms(self):\n",
        "        return len(self._transformation_list)\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _create_transformation_list(self):\n",
        "        return\n",
        "\n",
        "    def transform_batch(self, x_batch, t_inds):\n",
        "        assert len(x_batch) == len(t_inds)\n",
        "\n",
        "        transformed_batch = x_batch.copy()\n",
        "        for i, t_ind in enumerate(t_inds):\n",
        "            transformed_batch[i] = self._transformation_list[t_ind](transformed_batch[i])\n",
        "        return transformed_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "totupBB0M1PE"
      },
      "outputs": [],
      "source": [
        "class Transformer(AbstractTransformer):\n",
        "    def __init__(self, translation_x=8, translation_y=8):\n",
        "        self.max_tx = translation_x\n",
        "        self.max_ty = translation_y\n",
        "        super().__init__()\n",
        "\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, tx, ty, k_rotate in itertools.product((False, True),\n",
        "                                                           (0, -self.max_tx, self.max_tx),\n",
        "                                                           (0, -self.max_ty, self.max_ty),\n",
        "                                                           range(4)):\n",
        "            transformation = AffineTransformation(is_flip, tx, ty, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "\n",
        "        self._transformation_list = transformation_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JFHtMXniM4nl"
      },
      "outputs": [],
      "source": [
        "class SimpleTransformer(AbstractTransformer):\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, k_rotate in itertools.product((False, True),\n",
        "                                                    range(4)):\n",
        "            transformation = AffineTransformation(is_flip, 0, 0, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "\n",
        "        self._transformation_list = transformation_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO5wCGPjM9zT"
      },
      "source": [
        "## **The Model: Wide Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QW0y3hiLM8bC"
      },
      "outputs": [],
      "source": [
        "def initial_conv(input):\n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df2kvANONx2t"
      },
      "source": [
        "## **Experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IpVXqZTTN-Hi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from multiprocessing import Manager, freeze_support, Process\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "from scipy.special import psi, polygamma\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from joblib import Parallel, delayed\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KIOm47AHOIOj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from keras.datasets import mnist, fashion_mnist, cifar100, cifar10\n",
        "from keras.backend import cast_to_floatx\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XSJ4PYiINJwB"
      },
      "outputs": [],
      "source": [
        "def _train_ocsvm_and_score(params, xtrain, test_labels, xtest):\n",
        "    return roc_auc_score(test_labels, OneClassSVM(**params).fit(xtrain).decision_function(xtest))\n",
        "def _raw_ocsvm_experiment(dataset_load_fn, dataset_name, single_class_ind, gpu_q):\n",
        "    print('Class:', single_class_ind)\n",
        "    gpu_to_use = gpu_q.get()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_to_use\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = dataset_load_fn()\n",
        "    x_train = x_train[:TRAIN_SIZE]\n",
        "    y_train =  y_train[:TRAIN_SIZE]\n",
        "    x_test =  x_test[:VAL_SIZE]\n",
        "    y_test =  y_test[:VAL_SIZE]\n",
        "\n",
        "    x_train = x_train.reshape((len(x_train), -1))\n",
        "    x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "    x_train_task = x_train[y_train.flatten() == single_class_ind]\n",
        "\n",
        "    pg = ParameterGrid({'nu': np.linspace(0.1, 0.9, num=9),\n",
        "                        'gamma': np.logspace(-7, 2, num=10, base=2)})\n",
        "\n",
        "    results = Parallel(n_jobs=6)(\n",
        "        delayed(_train_ocsvm_and_score)(d, x_train_task, y_test.flatten() == single_class_ind, x_test)\n",
        "        for d in pg)\n",
        "\n",
        "    best_params, best_auc_score = max(zip(pg, results), key=lambda t: t[-1])\n",
        "    best_ocsvm = OneClassSVM(**best_params).fit(x_train_task)\n",
        "    scores = best_ocsvm.decision_function(x_test)\n",
        "    labels = y_test.flatten() == single_class_ind\n",
        "\n",
        "    save_roc_pr_curve_data(scores, labels)\n",
        "\n",
        "    gpu_q.put(gpu_to_use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CzJ1wKT7OatO"
      },
      "outputs": [],
      "source": [
        "def run_experiments(load_dataset_fn, dataset_name, q, n_classes):\n",
        "    print(\"START _transformations_experiment \")\n",
        "    # CAE OC-SVM\n",
        "    n_runs = 1\n",
        "    for i in range(n_runs):\n",
        "        print('Run Number:',i+1)\n",
        "        processes = [Process(target=_raw_ocsvm_experiment,\n",
        "                         args=(load_dataset_fn, dataset_name, c, q)) for c in range(n_classes)]\n",
        "        for p in processes:\n",
        "            p.start()\n",
        "            p.join()\n",
        "    print(\"END _transformations_experiment \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bOqhuKeYOrEm"
      },
      "outputs": [],
      "source": [
        "RESULTS_DIR = ''\n",
        "TRAIN_SIZE = 10000\n",
        "VAL_SIZE = 1000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t_3zJdh_O0XD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65cdd672-221f-4625-c1e3-73993d41a69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START _transformations_experiment \n",
            "Run Number: 1\n",
            "Class: 0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "roc_auc 0.9954098360655738\n",
            "pr_auc_norm where normal is the positive class 0.9652535753796309\n",
            "pr_auc_norm where anomaly is the positive class 0.9995626610129229\n",
            "Class: 1\n",
            "roc_auc 0.9991645781119466\n",
            "pr_auc_norm where normal is the positive class 0.9962874817775142\n",
            "pr_auc_norm where anomaly is the positive class 0.9998742033201039\n",
            "Class: 2\n",
            "roc_auc 0.8850444687158684\n",
            "pr_auc_norm where normal is the positive class 0.5270990052340319\n",
            "pr_auc_norm where anomaly is the positive class 0.9839206252701664\n",
            "Class: 3\n",
            "roc_auc 0.8907599083212107\n",
            "pr_auc_norm where normal is the positive class 0.604247904809104\n",
            "pr_auc_norm where anomaly is the positive class 0.9847922660097714\n",
            "Class: 4\n",
            "roc_auc 0.9546475995914199\n",
            "pr_auc_norm where normal is the positive class 0.7764566171051646\n",
            "pr_auc_norm where anomaly is the positive class 0.993865486613277\n",
            "Class: 5\n",
            "roc_auc 0.911709534061009\n",
            "pr_auc_norm where normal is the positive class 0.674687073473947\n",
            "pr_auc_norm where anomaly is the positive class 0.9894214273392096\n",
            "Class: 6\n",
            "roc_auc 0.9706537749745062\n",
            "pr_auc_norm where normal is the positive class 0.9056102821935716\n",
            "pr_auc_norm where anomaly is the positive class 0.9966144460268358\n",
            "Class: 7\n",
            "roc_auc 0.9505151403042634\n",
            "pr_auc_norm where normal is the positive class 0.7951860086699395\n",
            "pr_auc_norm where anomaly is the positive class 0.9940437926872991\n",
            "Class: 8\n",
            "roc_auc 0.8647738625291382\n",
            "pr_auc_norm where normal is the positive class 0.5682719684849653\n",
            "pr_auc_norm where anomaly is the positive class 0.9811197069797676\n",
            "Class: 9\n",
            "roc_auc 0.9630477666619698\n",
            "pr_auc_norm where normal is the positive class 0.7972938595415217\n",
            "pr_auc_norm where anomaly is the positive class 0.9955552232714644\n",
            "END _transformations_experiment \n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    freeze_support()\n",
        "    N_GPUS = 1\n",
        "    man = Manager()\n",
        "    q = man.Queue(N_GPUS)\n",
        "    for g in range(N_GPUS):\n",
        "        q.put(str(g))\n",
        "\n",
        "    experiments_list = [\n",
        "        (load_mnist, 'mnist', 10),\n",
        "    ]\n",
        "\n",
        "    for data_load_fn, dataset_name, n_classes in experiments_list:\n",
        "        run_experiments(data_load_fn, dataset_name, q, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1xcuNgKkDM9I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}