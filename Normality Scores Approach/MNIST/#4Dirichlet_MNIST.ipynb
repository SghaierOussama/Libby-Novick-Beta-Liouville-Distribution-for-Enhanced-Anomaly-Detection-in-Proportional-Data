{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUGw6b2-LJre"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from keras.datasets import mnist, fashion_mnist, cifar100, cifar10\n",
        "from keras.backend import cast_to_floatx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0MHJ4pVLoec"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.normalization.batch_normalization_v1 import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "weight_decay = 0.000005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi93ip8mLuBm"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "import itertools\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import apply_affine_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqege8c9MAiX"
      },
      "source": [
        "## **Load and Preprocessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgXT02KNLzm6"
      },
      "outputs": [],
      "source": [
        "def resize_and_crop_image(input_file, output_side_length, greyscale=False):\n",
        "    img = cv2.imread(input_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB if not greyscale else cv2.COLOR_BGR2GRAY)\n",
        "    height, width = img.shape[:2]\n",
        "    new_height = output_side_length\n",
        "    new_width = output_side_length\n",
        "    if height > width:\n",
        "        new_height = int(output_side_length * height / width)\n",
        "    else:\n",
        "        new_width = int(output_side_length * width / height)\n",
        "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "    height_offset = (new_height - output_side_length) // 2\n",
        "    width_offset = (new_width - output_side_length) // 2\n",
        "    cropped_img = resized_img[height_offset:height_offset + output_side_length,\n",
        "                              width_offset:width_offset + output_side_length]\n",
        "    assert cropped_img.shape[:2] == (output_side_length, output_side_length)\n",
        "    return cropped_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoWPCnk3MOa1"
      },
      "outputs": [],
      "source": [
        "def normalize_minus1_1(data):\n",
        "    return 2*(data/255.) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHgParnmMRw7"
      },
      "outputs": [],
      "source": [
        "def get_channels_axis():\n",
        "  import keras\n",
        "  idf = keras.backend.image_data_format()\n",
        "  if idf == 'channels_first':\n",
        "      return 1\n",
        "  assert idf == 'channels_last'\n",
        "  return 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygY-qVKqMVB3"
      },
      "outputs": [],
      "source": [
        "def load_mnist():\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = normalize_minus1_1(cast_to_floatx(np.pad(X_train, ((0, 0), (2, 2), (2, 2)), 'constant')))\n",
        "    X_train = np.expand_dims(X_train, axis=get_channels_axis())\n",
        "    X_test = normalize_minus1_1(cast_to_floatx(np.pad(X_test, ((0, 0), (2, 2), (2, 2)), 'constant')))\n",
        "    X_test = np.expand_dims(X_test, axis=get_channels_axis())\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWSgtZ8C8eoe"
      },
      "outputs": [],
      "source": [
        "def load_cifar10():\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    X_train = normalize_minus1_1(cast_to_floatx(X_train))\n",
        "    X_test = normalize_minus1_1(cast_to_floatx(X_test))\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZL18EvHMl8b"
      },
      "source": [
        "## **Saving the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7NtHmLmMfoN"
      },
      "outputs": [],
      "source": [
        "def roc_pr_curve_data(scores, labels):\n",
        "    scores = scores.flatten()\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    scores_pos = scores[labels == 1]\n",
        "    scores_neg = scores[labels != 1]\n",
        "\n",
        "    truth = np.concatenate((np.zeros_like(scores_neg), np.ones_like(scores_pos)))\n",
        "    preds = np.concatenate((scores_neg, scores_pos))\n",
        "    fpr, tpr, roc_thresholds = roc_curve(truth, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc\",roc_auc)\n",
        "\n",
        "    # pr curve where \"normal\" is the positive class\n",
        "    precision_norm, recall_norm, pr_thresholds_norm = precision_recall_curve(truth, preds)\n",
        "    pr_auc_norm = auc(recall_norm, precision_norm)\n",
        "    print(\"pr_auc_norm where normal is the positive class\",pr_auc_norm)\n",
        "\n",
        "    # pr curve where \"anomaly\" is the positive class\n",
        "    precision_anom, recall_anom, pr_thresholds_anom = precision_recall_curve(truth, -preds, pos_label=0)\n",
        "    pr_auc_anom = auc(recall_anom, precision_anom)\n",
        "    print(\"pr_auc_norm where anomaly is the positive class\",pr_auc_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEuib19NZ26"
      },
      "outputs": [],
      "source": [
        "def get_class_name_from_index(index, dataset_name):\n",
        "    ind_to_name = {\n",
        "        'cifar10': ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'),\n",
        "        'cifar100': ('aquatic mammals', 'fish', 'flowers', 'food containers', 'fruit and vegetables',\n",
        "                     'household electrical devices', 'household furniture', 'insects', 'large carnivores',\n",
        "                     'large man-made outdoor things', 'large natural outdoor scenes', 'large omnivores and herbivores',\n",
        "                     'medium-sized mammals', 'non-insect invertebrates', 'people', 'reptiles', 'small mammals', 'trees',\n",
        "                     'vehicles 1', 'vehicles 2'),\n",
        "        'fashion-mnist': ('t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag',\n",
        "                          'ankle-boot'),\n",
        "        'cats-vs-dogs': ('cat', 'dog'),\n",
        "    }\n",
        "\n",
        "    return ind_to_name[dataset_name][index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA18t2j0Mq9Z"
      },
      "source": [
        "## **Transformations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOM4GuZqMqDS"
      },
      "outputs": [],
      "source": [
        "class AffineTransformation(object):\n",
        "    def __init__(self, flip, tx, ty, k_90_rotate):\n",
        "        self.flip = flip\n",
        "        self.tx = tx\n",
        "        self.ty = ty\n",
        "        self.k_90_rotate = k_90_rotate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        res_x = x\n",
        "        if self.flip:\n",
        "            res_x = np.fliplr(res_x)\n",
        "        if self.tx != 0 or self.ty != 0:\n",
        "            res_x = apply_affine_transform(res_x, tx=self.tx, ty=self.ty,row_axis=0,\n",
        "    col_axis=1, channel_axis=2, fill_mode='reflect')\n",
        "        if self.k_90_rotate != 0:\n",
        "            res_x = np.rot90(res_x, self.k_90_rotate)\n",
        "\n",
        "        return res_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QRX0FkLMybA"
      },
      "outputs": [],
      "source": [
        "class AbstractTransformer(abc.ABC):\n",
        "    def __init__(self):\n",
        "        self._transformation_list = None\n",
        "        self._create_transformation_list()\n",
        "\n",
        "    @property\n",
        "    def n_transforms(self):\n",
        "        return len(self._transformation_list)\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _create_transformation_list(self):\n",
        "        return\n",
        "\n",
        "    def transform_batch(self, x_batch, t_inds):\n",
        "        assert len(x_batch) == len(t_inds)\n",
        "\n",
        "        transformed_batch = x_batch.copy()\n",
        "        for i, t_ind in enumerate(t_inds):\n",
        "            transformed_batch[i] = self._transformation_list[t_ind](transformed_batch[i])\n",
        "        return transformed_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "totupBB0M1PE"
      },
      "outputs": [],
      "source": [
        "class Transformer(AbstractTransformer):\n",
        "    def __init__(self, translation_x=8, translation_y=8):\n",
        "        self.max_tx = translation_x\n",
        "        self.max_ty = translation_y\n",
        "        super().__init__()\n",
        "\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, tx, ty, k_rotate in itertools.product((False, True),\n",
        "                                                           (0, -self.max_tx, self.max_tx),\n",
        "                                                           (0, -self.max_ty, self.max_ty),\n",
        "                                                           range(4)):\n",
        "            transformation = AffineTransformation(is_flip, tx, ty, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "\n",
        "        self._transformation_list = transformation_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFHtMXniM4nl"
      },
      "outputs": [],
      "source": [
        "class SimpleTransformer(AbstractTransformer):\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, k_rotate in itertools.product((False, True),\n",
        "                                                    range(4)):\n",
        "            transformation = AffineTransformation(is_flip, 0, 0, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "\n",
        "        self._transformation_list = transformation_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO5wCGPjM9zT"
      },
      "source": [
        "## **The Model: Wide Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW0y3hiLM8bC"
      },
      "outputs": [],
      "source": [
        "def initial_conv(input):\n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"th\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df2kvANONx2t"
      },
      "source": [
        "## **Experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpVXqZTTN-Hi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from multiprocessing import Manager, freeze_support, Process\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "from scipy.special import psi, polygamma\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from joblib import Parallel, delayed\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIOm47AHOIOj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from keras.datasets import mnist, fashion_mnist, cifar100, cifar10\n",
        "from keras.backend import cast_to_floatx\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSJ4PYiINJwB"
      },
      "outputs": [],
      "source": [
        "def _transformations_experiment(dataset_load_fn, dataset_name, single_class_ind, gpu_q):\n",
        "    gpu_to_use = gpu_q.get()\n",
        "    print('training class:',single_class_ind)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_to_use\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = dataset_load_fn()\n",
        "    x_train = x_train[:TRAIN_SIZE]\n",
        "    y_train =  y_train[:TRAIN_SIZE]\n",
        "    x_test =  x_test[:VAL_SIZE]\n",
        "    y_test =  y_test[:VAL_SIZE]\n",
        "    transformer = Transformer(8, 8)\n",
        "    n, k = (10, 4)\n",
        "    mdl = create_wide_residual_network(x_train.shape[1:], transformer.n_transforms, n, k)\n",
        "    mdl.compile('adam',\n",
        "                'categorical_crossentropy',\n",
        "                ['acc'])\n",
        "\n",
        "    x_train_task = x_train[y_train.flatten() == single_class_ind]\n",
        "    transformations_inds = np.tile(np.arange(transformer.n_transforms), len(x_train_task))\n",
        "    print('Start of the proposed transformation')\n",
        "    x_train_task_transformed = transformer.transform_batch(np.repeat(x_train_task, transformer.n_transforms, axis=0),\n",
        "                                                           transformations_inds)\n",
        "    print('End of the proposed transformation')\n",
        "    batch_size = 128\n",
        "    print('Start of the training')\n",
        "    mdl.fit(x=x_train_task_transformed, y=to_categorical(transformations_inds),\n",
        "            batch_size=128, epochs= N_EPOCHS #int(np.ceil(200/transformer.n_transforms))\n",
        "            )\n",
        "    print('End of the training')\n",
        "\n",
        "    def calc_approx_alpha_sum(observations):\n",
        "        N = len(observations)\n",
        "        f = np.mean(observations, axis=0)\n",
        "\n",
        "        return (N * (len(f) - 1) * (-psi(1))) / (\n",
        "                N * np.sum(f * np.log(f)) - np.sum(f * np.sum(np.log(observations), axis=0)))\n",
        "\n",
        "    def inv_psi(y, iters=5):\n",
        "        # initial estimate\n",
        "        cond = y >= -2.22\n",
        "        x = cond * (np.exp(y) + 0.5) + (1 - cond) * -1 / (y - psi(1))\n",
        "\n",
        "        for _ in range(iters):\n",
        "            x = x - (psi(x) - y) / polygamma(1, x)\n",
        "        return x\n",
        "\n",
        "    def fixed_point_dirichlet_mle(alpha_init, log_p_hat, max_iter=10):\n",
        "        alpha_new = alpha_old = alpha_init\n",
        "        for _ in range(max_iter):\n",
        "            alpha_new = inv_psi(np.clip(psi(np.clip(np.sum(alpha_old),10**(-10),None)) + log_p_hat,None,10))\n",
        "            if np.sqrt(np.sum((alpha_old - alpha_new) ** 2)) < 1e-5:\n",
        "                break\n",
        "            alpha_old = alpha_new\n",
        "        return alpha_new\n",
        "\n",
        "    def dirichlet_normality_score(alpha, p):\n",
        "        return np.sum((alpha - 1) * np.log(p), axis=-1)\n",
        "\n",
        "    scores = np.zeros((len(x_test),))\n",
        "    observed_data = x_train_task\n",
        "    for t_ind in range(transformer.n_transforms):\n",
        "        observed_dirichlet = mdl.predict(transformer.transform_batch(observed_data, [t_ind] * len(observed_data)),\n",
        "                                         batch_size=64)\n",
        "        log_p_hat_train = np.log(np.clip(observed_dirichlet,10**(-10),1)).mean(axis=0)\n",
        "\n",
        "        alpha_sum_approx = calc_approx_alpha_sum(observed_dirichlet)\n",
        "        alpha_sum_approx = np.clip(alpha_sum_approx, None,10**7)\n",
        "        alpha_0 = observed_dirichlet.mean(axis=0) * alpha_sum_approx\n",
        "        alpha_0 = np.nan_to_num(alpha_0, copy=True, nan=10**3, posinf=10**5, neginf=-(10**5))\n",
        "        #alpha_0 = np.ones(observed_dirichlet.shape[1])\n",
        "\n",
        "        mle_alpha_t = fixed_point_dirichlet_mle(alpha_0, log_p_hat_train)\n",
        "        mle_alpha_t = np.nan_to_num(mle_alpha_t, copy=True, nan=10**3, posinf=10**5, neginf=-(10**5))\n",
        "\n",
        "        x_test_p = mdl.predict(transformer.transform_batch(x_test, [t_ind] * len(x_test)),\n",
        "                               batch_size=64)\n",
        "        scores += dirichlet_normality_score(mle_alpha_t, x_test_p)\n",
        "        scores = np.nan_to_num(scores, copy=True, nan=10**7, posinf=10**10, neginf=-(10**10))\n",
        "\n",
        "    scores /= transformer.n_transforms\n",
        "    labels = y_test.flatten() == single_class_ind\n",
        "    roc_pr_curve_data(scores, labels)\n",
        "\n",
        "    gpu_q.put(gpu_to_use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzJ1wKT7OatO"
      },
      "outputs": [],
      "source": [
        "def run_experiments(load_dataset_fn, dataset_name, q, n_classes):\n",
        "    print(\"START _transformations_experiment \")\n",
        "    n_runs = 1\n",
        "    # Transformations\n",
        "    for i in range(n_runs):\n",
        "        print(\"Run number:\",i+1)\n",
        "        processes = [Process(target=_transformations_experiment,\n",
        "                             args=(load_dataset_fn, dataset_name, c, q)) for c in range(n_classes)]\n",
        "        if dataset_name in ['cats-vs-dogs']:  # Self-labeled set is memory consuming\n",
        "            for p in processes:\n",
        "                p.start()\n",
        "                p.join()\n",
        "        else:\n",
        "            for p in processes:\n",
        "                p.start()\n",
        "            for p in processes:\n",
        "                p.join()\n",
        "    print(\"END _transformations_experiment \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOqhuKeYOrEm"
      },
      "outputs": [],
      "source": [
        "RESULTS_DIR = ''\n",
        "TRAIN_SIZE = 10000\n",
        "VAL_SIZE = 1000\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_3zJdh_O0XD",
        "outputId": "889bb9f6-d378-4ed4-fc31-8f1d23224ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START _transformations_experiment \n",
            "Run number: 1\n",
            "training class: 0\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "564/564 [==============================] - 228s 335ms/step - loss: 1.7635 - acc: 0.3942\n",
            "Epoch 2/5\n",
            "564/564 [==============================] - 188s 333ms/step - loss: 0.6143 - acc: 0.8053\n",
            "Epoch 3/5\n",
            "564/564 [==============================] - 187s 332ms/step - loss: 0.3298 - acc: 0.9145\n",
            "Epoch 4/5\n",
            "564/564 [==============================] - 187s 331ms/step - loss: 0.2142 - acc: 0.9556\n",
            "Epoch 5/5\n",
            "564/564 [==============================] - 186s 331ms/step - loss: 0.1497 - acc: 0.9761\n",
            "End of the training\n",
            "16/16 [==============================] - 2s 72ms/step\n",
            "16/16 [==============================] - 1s 73ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.9140855030536805\n",
            "pr_auc_norm where normal is the positive class 0.8156087537455661\n",
            "pr_auc_norm where anomaly is the positive class 0.9847884277734322\n",
            "training class: 1\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "634/634 [==============================] - 252s 337ms/step - loss: 1.3669 - acc: 0.5915\n",
            "Epoch 2/5\n",
            "634/634 [==============================] - 210s 332ms/step - loss: 0.4736 - acc: 0.8615\n",
            "Epoch 3/5\n",
            "634/634 [==============================] - 210s 331ms/step - loss: 0.3289 - acc: 0.9120\n",
            "Epoch 4/5\n",
            "634/634 [==============================] - 209s 330ms/step - loss: 0.2326 - acc: 0.9446\n",
            "Epoch 5/5\n",
            "634/634 [==============================] - 209s 330ms/step - loss: 0.1710 - acc: 0.9651\n",
            "End of the training\n",
            "18/18 [==============================] - 3s 68ms/step\n",
            "16/16 [==============================] - 1s 73ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "18/18 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "18/18 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "18/18 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.855072463768116\n",
            "pr_auc_norm where normal is the positive class 0.5205474859217156\n",
            "pr_auc_norm where anomaly is the positive class 0.9700734757058167\n",
            "training class: 2\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "558/558 [==============================] - 228s 339ms/step - loss: 1.0885 - acc: 0.7598\n",
            "Epoch 2/5\n",
            "558/558 [==============================] - 188s 337ms/step - loss: 0.1796 - acc: 0.9717\n",
            "Epoch 3/5\n",
            "558/558 [==============================] - 188s 337ms/step - loss: 0.1306 - acc: 0.9839\n",
            "Epoch 4/5\n",
            "558/558 [==============================] - 187s 336ms/step - loss: 0.1053 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "558/558 [==============================] - 187s 335ms/step - loss: 0.0966 - acc: 0.9911\n",
            "End of the training\n",
            "16/16 [==============================] - 3s 67ms/step\n",
            "16/16 [==============================] - 1s 71ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "roc_auc 0.9940708378842252\n",
            "pr_auc_norm where normal is the positive class 0.9547669954320926\n",
            "pr_auc_norm where anomaly is the positive class 0.9992370431189161\n",
            "training class: 3\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformationStart of the training\n",
            "\n",
            "Epoch 1/5\n",
            "581/581 [==============================] - 236s 339ms/step - loss: 1.2096 - acc: 0.6355\n",
            "Epoch 2/5\n",
            "581/581 [==============================] - 195s 336ms/step - loss: 0.2690 - acc: 0.9373\n",
            "Epoch 3/5\n",
            "581/581 [==============================] - 195s 336ms/step - loss: 0.1953 - acc: 0.9587\n",
            "Epoch 4/5\n",
            "581/581 [==============================] - 195s 335ms/step - loss: 0.1504 - acc: 0.9721\n",
            "Epoch 5/5\n",
            "581/581 [==============================] - 195s 335ms/step - loss: 0.1159 - acc: 0.9830\n",
            "End of the training\n",
            "17/17 [==============================] - 2s 63ms/step\n",
            "16/16 [==============================] - 1s 70ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "roc_auc 0.9601469372377056\n",
            "pr_auc_norm where normal is the positive class 0.8715362688371032\n",
            "pr_auc_norm where anomaly is the positive class 0.9937196563874615\n",
            "training class: 4\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "552/552 [==============================] - 225s 338ms/step - loss: 1.0060 - acc: 0.7949\n",
            "Epoch 2/5\n",
            "552/552 [==============================] - 185s 336ms/step - loss: 0.1487 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "552/552 [==============================] - 186s 336ms/step - loss: 0.1114 - acc: 0.9899\n",
            "Epoch 4/5\n",
            "552/552 [==============================] - 185s 336ms/step - loss: 0.0876 - acc: 0.9944\n",
            "Epoch 5/5\n",
            "552/552 [==============================] - 185s 335ms/step - loss: 0.0850 - acc: 0.9937\n",
            "End of the training\n",
            "16/16 [==============================] - 2s 64ms/step\n",
            "16/16 [==============================] - 1s 73ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.9872012257405516\n",
            "pr_auc_norm where normal is the positive class 0.9394389247662245\n",
            "pr_auc_norm where anomaly is the positive class 0.9983013320950636\n",
            "training class: 5\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "486/486 [==============================] - 202s 339ms/step - loss: 1.2510 - acc: 0.6665\n",
            "Epoch 2/5\n",
            "486/486 [==============================] - 163s 336ms/step - loss: 0.1867 - acc: 0.9691\n",
            "Epoch 3/5\n",
            "486/486 [==============================] - 163s 336ms/step - loss: 0.1342 - acc: 0.9819\n",
            "Epoch 4/5\n",
            "486/486 [==============================] - 163s 336ms/step - loss: 0.1122 - acc: 0.9875\n",
            "Epoch 5/5\n",
            "486/486 [==============================] - 163s 336ms/step - loss: 0.0936 - acc: 0.9923\n",
            "End of the training\n",
            "14/14 [==============================] - 2s 69ms/step\n",
            "16/16 [==============================] - 1s 73ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 53ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "14/14 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "roc_auc 0.9835706462212486\n",
            "pr_auc_norm where normal is the positive class 0.8783575412769061\n",
            "pr_auc_norm where anomaly is the positive class 0.998389403361871\n",
            "training class: 6\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "571/571 [==============================] - 230s 339ms/step - loss: 0.8726 - acc: 0.8565\n",
            "Epoch 2/5\n",
            "571/571 [==============================] - 192s 336ms/step - loss: 0.1175 - acc: 0.9919\n",
            "Epoch 3/5\n",
            "571/571 [==============================] - 192s 336ms/step - loss: 0.0921 - acc: 0.9950\n",
            "Epoch 4/5\n",
            "571/571 [==============================] - 192s 336ms/step - loss: 0.0780 - acc: 0.9963\n",
            "Epoch 5/5\n",
            "571/571 [==============================] - 191s 335ms/step - loss: 0.0698 - acc: 0.9968\n",
            "End of the training\n",
            "16/16 [==============================] - 2s 72ms/step\n",
            "16/16 [==============================] - 1s 70ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.9998866941118707\n",
            "pr_auc_norm where normal is the positive class 0.9988767087311201\n",
            "pr_auc_norm where anomaly is the positive class 0.9999891852012036\n",
            "training class: 7\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "602/602 [==============================] - 242s 339ms/step - loss: 0.8699 - acc: 0.8579\n",
            "Epoch 2/5\n",
            "602/602 [==============================] - 202s 336ms/step - loss: 0.1680 - acc: 0.9741\n",
            "Epoch 3/5\n",
            "602/602 [==============================] - 202s 336ms/step - loss: 0.1302 - acc: 0.9821\n",
            "Epoch 4/5\n",
            "602/602 [==============================] - 202s 335ms/step - loss: 0.1068 - acc: 0.9867\n",
            "Epoch 5/5\n",
            "602/602 [==============================] - 202s 335ms/step - loss: 0.0912 - acc: 0.9896\n",
            "End of the training\n",
            "17/17 [==============================] - 2s 69ms/step\n",
            "16/16 [==============================] - 1s 74ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "17/17 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "17/17 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.9558739447751656\n",
            "pr_auc_norm where normal is the positive class 0.6762340803079052\n",
            "pr_auc_norm where anomaly is the positive class 0.9950799439411979\n",
            "training class: 8\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "531/531 [==============================] - 214s 335ms/step - loss: 1.3982 - acc: 0.6274\n",
            "Epoch 2/5\n",
            "531/531 [==============================] - 176s 332ms/step - loss: 0.3258 - acc: 0.9206\n",
            "Epoch 3/5\n",
            "531/531 [==============================] - 176s 331ms/step - loss: 0.1775 - acc: 0.9700\n",
            "Epoch 4/5\n",
            "531/531 [==============================] - 175s 330ms/step - loss: 0.1282 - acc: 0.9841\n",
            "Epoch 5/5\n",
            "531/531 [==============================] - 175s 330ms/step - loss: 0.1059 - acc: 0.9896\n",
            "End of the training\n",
            "15/15 [==============================] - 2s 76ms/step\n",
            "16/16 [==============================] - 1s 74ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 52ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "15/15 [==============================] - 1s 52ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "15/15 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.9294761898888738\n",
            "pr_auc_norm where normal is the positive class 0.685518482694195\n",
            "pr_auc_norm where anomaly is the positive class 0.9907471374392032\n",
            "training class: 9\n",
            "Wide Residual Network-64-4 created.\n",
            "Start of the proposed transformation\n",
            "End of the proposed transformation\n",
            "Start of the training\n",
            "Epoch 1/5\n",
            "551/551 [==============================] - 226s 339ms/step - loss: 0.8845 - acc: 0.8613\n",
            "Epoch 2/5\n",
            "551/551 [==============================] - 186s 337ms/step - loss: 0.1300 - acc: 0.9887\n",
            "Epoch 3/5\n",
            "551/551 [==============================] - 185s 336ms/step - loss: 0.0986 - acc: 0.9941\n",
            "Epoch 4/5\n",
            "551/551 [==============================] - 186s 337ms/step - loss: 0.0858 - acc: 0.9954\n",
            "Epoch 5/5\n",
            "551/551 [==============================] - 185s 336ms/step - loss: 0.0762 - acc: 0.9959\n",
            "End of the training\n",
            "16/16 [==============================] - 2s 64ms/step\n",
            "16/16 [==============================] - 1s 71ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 51ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 48ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 49ms/step\n",
            "16/16 [==============================] - 1s 50ms/step\n",
            "roc_auc 0.9909116528110469\n",
            "pr_auc_norm where normal is the positive class 0.936782065502445\n",
            "pr_auc_norm where anomaly is the positive class 0.9990368006877507\n",
            "END _transformations_experiment \n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    freeze_support()\n",
        "    N_GPUS = 1\n",
        "    man = Manager()\n",
        "    q = man.Queue(N_GPUS)\n",
        "    for g in range(N_GPUS):\n",
        "        q.put(str(g))\n",
        "\n",
        "    experiments_list = [\n",
        "        (load_mnist, 'mnist', 10)\n",
        "    ]\n",
        "\n",
        "    for data_load_fn, dataset_name, n_classes in experiments_list:\n",
        "        run_experiments(data_load_fn, dataset_name, q, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MsbRJ-OPLpo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}