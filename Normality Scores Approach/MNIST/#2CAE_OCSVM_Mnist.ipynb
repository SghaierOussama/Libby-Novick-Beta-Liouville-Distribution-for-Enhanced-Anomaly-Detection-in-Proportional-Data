{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rUGw6b2-LJre"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from keras.datasets import mnist, fashion_mnist, cifar100, cifar10\n",
        "from keras.backend import cast_to_floatx\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u0MHJ4pVLoec"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.normalization.batch_normalization_v1 import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "random.seed(0)\n",
        "weight_decay = 0.000005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yi93ip8mLuBm"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "import itertools\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import apply_affine_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqege8c9MAiX"
      },
      "source": [
        "## **Load and Preprocessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JgXT02KNLzm6"
      },
      "outputs": [],
      "source": [
        "def resize_and_crop_image(input_file, output_side_length, greyscale=False):\n",
        "    img = cv2.imread(input_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB if not greyscale else cv2.COLOR_BGR2GRAY)\n",
        "    height, width = img.shape[:2]\n",
        "    new_height = output_side_length\n",
        "    new_width = output_side_length\n",
        "    if height > width:\n",
        "        new_height = int(output_side_length * height / width)\n",
        "    else:\n",
        "        new_width = int(output_side_length * width / height)\n",
        "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "    height_offset = (new_height - output_side_length) // 2\n",
        "    width_offset = (new_width - output_side_length) // 2\n",
        "    cropped_img = resized_img[height_offset:height_offset + output_side_length,\n",
        "                              width_offset:width_offset + output_side_length]\n",
        "    assert cropped_img.shape[:2] == (output_side_length, output_side_length)\n",
        "    return cropped_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MoWPCnk3MOa1"
      },
      "outputs": [],
      "source": [
        "def normalize_minus1_1(data):\n",
        "    return 2*(data/255.) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lHgParnmMRw7"
      },
      "outputs": [],
      "source": [
        "def get_channels_axis():\n",
        "  import keras\n",
        "  idf = keras.backend.image_data_format()\n",
        "  if idf == 'channels_first':\n",
        "      return 1\n",
        "  assert idf == 'channels_last'\n",
        "  return 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ygY-qVKqMVB3"
      },
      "outputs": [],
      "source": [
        "def load_mnist():\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = normalize_minus1_1(cast_to_floatx(np.pad(X_train, ((0, 0), (2, 2), (2, 2)), 'constant')))\n",
        "    X_train = np.expand_dims(X_train, axis=get_channels_axis())\n",
        "    X_test = normalize_minus1_1(cast_to_floatx(np.pad(X_test, ((0, 0), (2, 2), (2, 2)), 'constant')))\n",
        "    X_test = np.expand_dims(X_test, axis=get_channels_axis())\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aVGJ2jWd6-9Z"
      },
      "outputs": [],
      "source": [
        "def load_cifar10():\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    X_train = normalize_minus1_1(cast_to_floatx(X_train))\n",
        "    X_test = normalize_minus1_1(cast_to_floatx(X_test))\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZL18EvHMl8b"
      },
      "source": [
        "## **Saving the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g7NtHmLmMfoN"
      },
      "outputs": [],
      "source": [
        "def save_roc_pr_curve_data(scores, labels):\n",
        "    scores = scores.flatten()\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    scores_pos = scores[labels == 1]\n",
        "    scores_neg = scores[labels != 1]\n",
        "\n",
        "    truth = np.concatenate((np.zeros_like(scores_neg), np.ones_like(scores_pos)))\n",
        "    preds = np.concatenate((scores_neg, scores_pos))\n",
        "    fpr, tpr, roc_thresholds = roc_curve(truth, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc\",roc_auc)\n",
        "\n",
        "    # pr curve where \"normal\" is the positive class\n",
        "    precision_norm, recall_norm, pr_thresholds_norm = precision_recall_curve(truth, preds)\n",
        "    pr_auc_norm = auc(recall_norm, precision_norm)\n",
        "    print(\"pr_auc_norm where normal is the positive class\",pr_auc_norm)\n",
        "\n",
        "    # pr curve where \"anomaly\" is the positive class\n",
        "    precision_anom, recall_anom, pr_thresholds_anom = precision_recall_curve(truth, -preds, pos_label=0)\n",
        "    pr_auc_anom = auc(recall_anom, precision_anom)\n",
        "    print(\"pr_auc_norm where anomaly is the positive class\",pr_auc_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IEEuib19NZ26"
      },
      "outputs": [],
      "source": [
        "def get_class_name_from_index(index, dataset_name):\n",
        "    ind_to_name = {\n",
        "        'fashion-mnist': ('t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag',\n",
        "                          'ankle-boot'),\n",
        "    }\n",
        "\n",
        "    return ind_to_name[dataset_name][index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA18t2j0Mq9Z"
      },
      "source": [
        "## **Transformations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zOM4GuZqMqDS"
      },
      "outputs": [],
      "source": [
        "class AffineTransformation(object):\n",
        "    def __init__(self, flip, tx, ty, k_90_rotate):\n",
        "        self.flip = flip\n",
        "        self.tx = tx\n",
        "        self.ty = ty\n",
        "        self.k_90_rotate = k_90_rotate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        res_x = x\n",
        "        if self.flip:\n",
        "            res_x = np.fliplr(res_x)\n",
        "        if self.tx != 0 or self.ty != 0:\n",
        "            res_x = apply_affine_transform(res_x, tx=self.tx, ty=self.ty,row_axis=0,\n",
        "    col_axis=1, channel_axis=2, fill_mode='reflect')\n",
        "        if self.k_90_rotate != 0:\n",
        "            res_x = np.rot90(res_x, self.k_90_rotate)\n",
        "\n",
        "        return res_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1QRX0FkLMybA"
      },
      "outputs": [],
      "source": [
        "class AbstractTransformer(abc.ABC):\n",
        "    def __init__(self):\n",
        "        self._transformation_list = None\n",
        "        self._create_transformation_list()\n",
        "\n",
        "    @property\n",
        "    def n_transforms(self):\n",
        "        return len(self._transformation_list)\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _create_transformation_list(self):\n",
        "        return\n",
        "\n",
        "    def transform_batch(self, x_batch, t_inds):\n",
        "        assert len(x_batch) == len(t_inds)\n",
        "\n",
        "        transformed_batch = x_batch.copy()\n",
        "        for i, t_ind in enumerate(t_inds):\n",
        "            transformed_batch[i] = self._transformation_list[t_ind](transformed_batch[i])\n",
        "        return transformed_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "totupBB0M1PE"
      },
      "outputs": [],
      "source": [
        "class Transformer(AbstractTransformer):\n",
        "    def __init__(self, translation_x=8, translation_y=8):\n",
        "        self.max_tx = translation_x\n",
        "        self.max_ty = translation_y\n",
        "        super().__init__()\n",
        "\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, tx, ty, k_rotate in itertools.product((False, True),\n",
        "                                                           (0, -self.max_tx, self.max_tx),\n",
        "                                                           (0, -self.max_ty, self.max_ty),\n",
        "                                                           range(4)):\n",
        "            transformation = AffineTransformation(is_flip, tx, ty, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "\n",
        "        self._transformation_list = transformation_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JFHtMXniM4nl"
      },
      "outputs": [],
      "source": [
        "class SimpleTransformer(AbstractTransformer):\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, k_rotate in itertools.product((False, True),\n",
        "                                                    range(4)):\n",
        "            transformation = AffineTransformation(is_flip, 0, 0, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "\n",
        "        self._transformation_list = transformation_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO5wCGPjM9zT"
      },
      "source": [
        "## **The Model: Wide Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PdBSbryzJLl3"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Flatten, Dense, Conv2DTranspose, Reshape\n",
        "\n",
        "\n",
        "def conv_encoder(input_side=32, n_channels=3, representation_dim=256, representation_activation='tanh',\n",
        "                 intermediate_activation='relu'):\n",
        "    nf = 64\n",
        "    input_shape = (n_channels, input_side, input_side) if get_channels_axis() == 1 else (input_side, input_side,\n",
        "                                                                                         n_channels)\n",
        "\n",
        "    x_in = Input(shape=input_shape)\n",
        "    enc = x_in\n",
        "\n",
        "    # downsample x0.5\n",
        "    enc = Conv2D(nf, kernel_size=(3, 3), strides=(2, 2), padding='same')(enc)\n",
        "    enc = BatchNormalization(axis=get_channels_axis())(enc)\n",
        "    enc = Activation(intermediate_activation)(enc)\n",
        "\n",
        "    # downsample x0.5\n",
        "    enc = Conv2D(nf * 2, kernel_size=(3, 3), strides=(2, 2), padding='same')(enc)\n",
        "    enc = BatchNormalization(axis=get_channels_axis())(enc)\n",
        "    enc = Activation(intermediate_activation)(enc)\n",
        "\n",
        "    # downsample x0.5\n",
        "    enc = Conv2D(nf * 4, kernel_size=(3, 3), strides=(2, 2), padding='same')(enc)\n",
        "    enc = BatchNormalization(axis=get_channels_axis())(enc)\n",
        "    enc = Activation(intermediate_activation)(enc)\n",
        "\n",
        "    if input_side == 64:\n",
        "        # downsample x0.5\n",
        "        enc = Conv2D(nf * 8, kernel_size=(3, 3), strides=(2, 2), padding='same')(enc)\n",
        "        enc = BatchNormalization(axis=get_channels_axis())(enc)\n",
        "        enc = Activation(intermediate_activation)(enc)\n",
        "\n",
        "    enc = Flatten()(enc)\n",
        "    rep = Dense(representation_dim, activation=representation_activation)(enc)\n",
        "\n",
        "    return Model(x_in, rep)\n",
        "\n",
        "\n",
        "def conv_decoder(output_side=32, n_channels=3, representation_dim=256, activation='relu'):\n",
        "    nf = 64\n",
        "\n",
        "    rep_in = Input(shape=(representation_dim,))\n",
        "\n",
        "    g = Dense(nf * 4 * 4 * 4)(rep_in)\n",
        "    g = BatchNormalization(axis=-1)(g)\n",
        "    g = Activation(activation)(g)\n",
        "\n",
        "    conv_shape = (nf * 4, 4, 4) if get_channels_axis() == 1 else (4, 4, nf * 4)\n",
        "    g = Reshape(conv_shape)(g)\n",
        "\n",
        "    # upsample x2\n",
        "    g = Conv2DTranspose(nf * 2, kernel_size=(3, 3), strides=(2, 2), padding='same')(g)\n",
        "    g = BatchNormalization(axis=get_channels_axis())(g)\n",
        "    g = Activation(activation)(g)\n",
        "\n",
        "    # upsample x2\n",
        "    g = Conv2DTranspose(nf, kernel_size=(3, 3), strides=(2, 2), padding='same')(g)\n",
        "    g = BatchNormalization(axis=get_channels_axis())(g)\n",
        "    g = Activation(activation)(g)\n",
        "\n",
        "    if output_side == 64:\n",
        "        # upsample x2\n",
        "        g = Conv2DTranspose(nf, kernel_size=(3, 3), strides=(2, 2), padding='same')(g)\n",
        "        g = BatchNormalization(axis=get_channels_axis())(g)\n",
        "        g = Activation(activation)(g)\n",
        "\n",
        "    # upsample x2\n",
        "    g = Conv2DTranspose(n_channels, kernel_size=(3, 3), strides=(2, 2), padding='same')(g)\n",
        "    g = Activation('tanh')(g)\n",
        "\n",
        "    return Model(rep_in, g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df2kvANONx2t"
      },
      "source": [
        "## **Experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IpVXqZTTN-Hi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from multiprocessing import Manager, freeze_support, Process\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "from scipy.special import psi, polygamma\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from joblib import Parallel, delayed\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KIOm47AHOIOj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from keras.datasets import mnist, fashion_mnist, cifar100, cifar10\n",
        "from keras.backend import cast_to_floatx\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XSJ4PYiINJwB"
      },
      "outputs": [],
      "source": [
        "def _train_ocsvm_and_score(params, xtrain, test_labels, xtest):\n",
        "    return roc_auc_score(test_labels, OneClassSVM(**params).fit(xtrain).decision_function(xtest))\n",
        "def _cae_ocsvm_experiment(dataset_load_fn, dataset_name, single_class_ind, gpu_q):\n",
        "    print('Class:', single_class_ind)\n",
        "    gpu_to_use = gpu_q.get()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_to_use\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = dataset_load_fn()\n",
        "    x_train = x_train[:TRAIN_SIZE]\n",
        "    y_train =  y_train[:TRAIN_SIZE]\n",
        "    x_test =  x_test[:VAL_SIZE]\n",
        "    y_test =  y_test[:VAL_SIZE]\n",
        "\n",
        "    n_channels = x_train.shape[get_channels_axis()]\n",
        "    input_side = x_train.shape[2]  # channel side will always be at shape[2]\n",
        "    enc = conv_encoder(input_side, n_channels)\n",
        "    dec = conv_decoder(input_side, n_channels)\n",
        "    x_in = Input(shape=x_train.shape[1:])\n",
        "    x_rec = dec(enc(x_in))\n",
        "    cae = Model(x_in, x_rec)\n",
        "    cae.compile('adam', 'mse')\n",
        "\n",
        "    x_train_task = x_train[y_train.flatten() == single_class_ind]\n",
        "    x_test_task = x_test[y_test.flatten() == single_class_ind]  # This is just for visual monitoring\n",
        "    cae.fit(x=x_train_task, y=x_train_task, batch_size=128, epochs=10, validation_data=(x_test_task, x_test_task))\n",
        "\n",
        "    x_train_task_rep = enc.predict(x_train_task, batch_size=128)\n",
        "\n",
        "    x_test_rep = enc.predict(x_test, batch_size=128)\n",
        "    pg = ParameterGrid({'nu': np.linspace(0.1, 0.9, num=9),\n",
        "                        'gamma': np.logspace(-7, 2, num=10, base=2)})\n",
        "\n",
        "    results = Parallel(n_jobs=6)(\n",
        "        delayed(_train_ocsvm_and_score)(d, x_train_task_rep, y_test.flatten() == single_class_ind, x_test_rep)\n",
        "        for d in pg)\n",
        "\n",
        "    best_params, best_auc_score = max(zip(pg, results), key=lambda t: t[-1])\n",
        "    best_ocsvm = OneClassSVM(**best_params).fit(x_train_task_rep)\n",
        "    scores = best_ocsvm.decision_function(x_test_rep)\n",
        "    labels = y_test.flatten() == single_class_ind\n",
        "\n",
        "    save_roc_pr_curve_data(scores, labels)\n",
        "\n",
        "    gpu_q.put(gpu_to_use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CzJ1wKT7OatO"
      },
      "outputs": [],
      "source": [
        "def run_experiments(load_dataset_fn, dataset_name, q, n_classes):\n",
        "    print(\"START _transformations_experiment \")\n",
        "    # CAE OC-SVM\n",
        "    n_runs = 1\n",
        "    for i in range(n_runs):\n",
        "        print('Run Number:',i+1)\n",
        "        processes = [Process(target=_cae_ocsvm_experiment,\n",
        "                         args=(load_dataset_fn, dataset_name, c, q)) for c in range(n_classes)]\n",
        "        for p in processes:\n",
        "            p.start()\n",
        "            p.join()\n",
        "    print(\"END _transformations_experiment \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bOqhuKeYOrEm"
      },
      "outputs": [],
      "source": [
        "RESULTS_DIR = ''\n",
        "TRAIN_SIZE = 10000\n",
        "VAL_SIZE = 1000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_3zJdh_O0XD",
        "outputId": "acfb7438-5ef1-4189-c8ff-36d01eb9d427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START _transformations_experiment \n",
            "Run Number: 1\n",
            "Class: 0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 21s 114ms/step - loss: 0.5226 - val_loss: 0.8812\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.2408 - val_loss: 0.7904\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1408 - val_loss: 0.6915\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0924 - val_loss: 0.6070\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0680 - val_loss: 0.5378\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0540 - val_loss: 0.4817\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0442 - val_loss: 0.4377\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0383 - val_loss: 0.4002\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0339 - val_loss: 0.3701\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0313 - val_loss: 0.3526\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "roc_auc 0.9725490196078431\n",
            "pr_auc_norm where normal is the positive class 0.8951834198560396\n",
            "pr_auc_norm where anomaly is the positive class 0.9968571145126119\n",
            "Class: 1\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 9s 123ms/step - loss: 0.8386 - val_loss: 0.9225\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.3464 - val_loss: 0.8107\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2161 - val_loss: 0.6660\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1470 - val_loss: 0.5147\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0992 - val_loss: 0.3844\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0644 - val_loss: 0.2811\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0422 - val_loss: 0.2227\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0298 - val_loss: 0.1877\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0238 - val_loss: 0.1697\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0200 - val_loss: 0.1558\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "roc_auc 0.9928716719334569\n",
            "pr_auc_norm where normal is the positive class 0.9852982969807682\n",
            "pr_auc_norm where anomaly is the positive class 0.9986867613874727\n",
            "Class: 2\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 8s 137ms/step - loss: 0.6359 - val_loss: 0.8907\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.3098 - val_loss: 0.8003\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1917 - val_loss: 0.6922\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1301 - val_loss: 0.5949\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0948 - val_loss: 0.5144\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0747 - val_loss: 0.4532\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0611 - val_loss: 0.4073\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0515 - val_loss: 0.3702\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0443 - val_loss: 0.3476\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0387 - val_loss: 0.3225\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "roc_auc 0.823392885005461\n",
            "pr_auc_norm where normal is the positive class 0.39549320534331966\n",
            "pr_auc_norm where anomaly is the positive class 0.972529267183811\n",
            "Class: 3\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 9s 97ms/step - loss: 0.8098 - val_loss: 0.8925\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.3749 - val_loss: 0.7991\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2553 - val_loss: 0.6778\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1831 - val_loss: 0.5617\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1368 - val_loss: 0.4730\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1047 - val_loss: 0.4083\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0778 - val_loss: 0.3681\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0634 - val_loss: 0.3380\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0562 - val_loss: 0.3126\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0498 - val_loss: 0.3009\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "roc_auc 0.7614676978786198\n",
            "pr_auc_norm where normal is the positive class 0.28591884538512813\n",
            "pr_auc_norm where anomaly is the positive class 0.9621111561364284\n",
            "Class: 4\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 9s 115ms/step - loss: 0.5339 - val_loss: 0.8931\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.2398 - val_loss: 0.7893\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1554 - val_loss: 0.6627\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1119 - val_loss: 0.5525\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0827 - val_loss: 0.4727\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0626 - val_loss: 0.4151\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0493 - val_loss: 0.3672\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0409 - val_loss: 0.3337\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0353 - val_loss: 0.3070\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0306 - val_loss: 0.2898\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "roc_auc 0.7939223697650665\n",
            "pr_auc_norm where normal is the positive class 0.40394150361247927\n",
            "pr_auc_norm where anomaly is the positive class 0.9670117346727928\n",
            "Class: 5\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 8s 131ms/step - loss: 0.6373 - val_loss: 0.8968\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2758 - val_loss: 0.8234\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1848 - val_loss: 0.7291\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1355 - val_loss: 0.6350\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1024 - val_loss: 0.5525\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0794 - val_loss: 0.4865\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0644 - val_loss: 0.4323\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0530 - val_loss: 0.3917\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0455 - val_loss: 0.3605\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0399 - val_loss: 0.3374\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "roc_auc 0.7835857536729992\n",
            "pr_auc_norm where normal is the positive class 0.39918220927737424\n",
            "pr_auc_norm where anomaly is the positive class 0.9716667173149672\n",
            "Class: 6\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 8s 117ms/step - loss: 0.7279 - val_loss: 0.8977\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3334 - val_loss: 0.8125\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.2045 - val_loss: 0.6953\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1356 - val_loss: 0.5852\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0975 - val_loss: 0.4994\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0772 - val_loss: 0.4421\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0629 - val_loss: 0.3998\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0522 - val_loss: 0.3687\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0452 - val_loss: 0.3402\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0396 - val_loss: 0.3283\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "roc_auc 0.8669033500774258\n",
            "pr_auc_norm where normal is the positive class 0.5755929614951983\n",
            "pr_auc_norm where anomaly is the positive class 0.9815139595943337\n",
            "Class: 7\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 9s 150ms/step - loss: 0.7342 - val_loss: 0.8937\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.2865 - val_loss: 0.7625\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.1665 - val_loss: 0.5905\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.1080 - val_loss: 0.4563\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0739 - val_loss: 0.3752\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0548 - val_loss: 0.3237\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.0449 - val_loss: 0.2908\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0375 - val_loss: 0.2685\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0331 - val_loss: 0.2546\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0298 - val_loss: 0.2429\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "roc_auc 0.8683169093823921\n",
            "pr_auc_norm where normal is the positive class 0.5844357872991077\n",
            "pr_auc_norm where anomaly is the positive class 0.9822528347498632\n",
            "Class:\n",
            " 8Epoch 1/10\n",
            "8/8 [==============================] - 9s 111ms/step - loss: 0.8416 - val_loss: 0.8935\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.4047 - val_loss: 0.8146\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.2779 - val_loss: 0.7099\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1954 - val_loss: 0.6052\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1374 - val_loss: 0.5158\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1003 - val_loss: 0.4558\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0794 - val_loss: 0.4041\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0651 - val_loss: 0.3704\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0556 - val_loss: 0.3425\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0479 - val_loss: 0.3290\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "roc_auc 0.7441507665363413\n",
            "pr_auc_norm where normal is the positive class 0.3058948625660636\n",
            "pr_auc_norm where anomaly is the positive class 0.9560518296599697\n",
            "Class: 9\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 10s 114ms/step - loss: 0.7180 - val_loss: 0.8980\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.2818 - val_loss: 0.8075\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1619 - val_loss: 0.6863\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1100 - val_loss: 0.5726\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0818 - val_loss: 0.4836\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0635 - val_loss: 0.4235\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0515 - val_loss: 0.3726\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0434 - val_loss: 0.3364\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0371 - val_loss: 0.3138\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0320 - val_loss: 0.2940\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "roc_auc 0.9248508759569771\n",
            "pr_auc_norm where normal is the positive class 0.6504731593571152\n",
            "pr_auc_norm where anomaly is the positive class 0.9908923962734684\n",
            "END _transformations_experiment \n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    freeze_support()\n",
        "    N_GPUS = 1\n",
        "    man = Manager()\n",
        "    q = man.Queue(N_GPUS)\n",
        "    for g in range(N_GPUS):\n",
        "        q.put(str(g))\n",
        "\n",
        "    experiments_list = [\n",
        "        (load_mnist, 'mnist', 10),\n",
        "    ]\n",
        "\n",
        "    for data_load_fn, dataset_name, n_classes in experiments_list:\n",
        "        run_experiments(data_load_fn, dataset_name, q, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1xcuNgKkDM9I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "gpu2",
      "language": "python",
      "name": "gpu2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}